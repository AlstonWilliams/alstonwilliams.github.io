---
layout: post
title: Spark写S3慢优化过程
date: 2019-06-08
author: AlstonWilliams
header-img: img/post-bg-2015.jpg
catalog: true
categories:
- Spark
tags:
- Spark
---

在跑客户的数据的时候，需要Spark插入数据到Hive中，而Hive又是布在S3上的。

Spark将数据插入Hive时，会先写到一个S3上的一个临时目录，最终再写到Hive对应的目录上。

而这儿就存在一个问题。在S3上，从一个临时目录移动到Hive的目录上，是特别耗费时间的。我们的程序，凌晨光做这个移动的过程，就做了6个小时。

想起来以前在看博客的时候，看到过[Apache Spark 2.0 在作业完成时却花费很长时间结束](https://www.iteblog.com/archives/2500.html)这么一个问题，跟我们现在的情况特别相似，就想用这个解决方案试一下，没想到在本地都成功不了。因为这个配置项要求hadoop的版本>2.7。想了解更多请看这篇StackOverflow: [Extremely slow S3 write times from EMR/ Spark - StackOverflow](https://stackoverflow.com/questions/42822483/extremely-slow-s3-write-times-from-emr-spark)

从另一篇文章中，看到了一个解决方案，就是先保存到HDFS中，然后再copy到S3上，这样子会快很多，[Spark 2.2.0 FileOutputCommitter](https://stackoverflow.com/questions/46261754/spark-2-2-0-fileoutputcommitter)

原来6个小时才能移动完，现在不到20分钟即可。
