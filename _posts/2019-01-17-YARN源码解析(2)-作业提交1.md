---
layout: post
title: YARN源码解析(2)-作业提交1
date: 2019-02-17
author: AlstonWilliams
header-img: img/post-bg-2015.jpg
catalog: true
categories:
- Hadoop
tags:
- Hadoop
---
最近在阅读Hadoop的源码，为了加深理解，就将其记录下来。

我们都知道，Hadoop主要由MapReduce实现，YARN，以及HDFS组成。所以，我会依次阅读MapReduce的实现，以及YARN，最后是HDFS的实现。

在这篇文章中，我们先介绍提交一个作业的时候发生了什么。

当我们运行一个作业的时候，我们都是通过:**$HADOOP_HOME/bin/hadoop your.jar main_class input output**这么一条命令来运行的。

通过查看**$HADOOP_HOME/bin/hadoop**这个文件的内容，我们能够发现，它是运行了一个**org.apache.hadoop.util.RunJar**这么一个类。

![](http://upload-images.jianshu.io/upload_images/4108852-b80a77301eb41013.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

那么这个类都做了什么呢？

其实没什么，打开它的源码，我们能够看到，只不过就是解压我们指定的jar文件，然后运行主类。

![](http://upload-images.jianshu.io/upload_images/4108852-066301727baeeca8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里有一点需要注意的是，有的jar文件是会包含**META-INF/MANIFEST.MF**这么一个文件的。而这个文件中可以指定Jar文件的主类。

从**org.apache.hadoop.util.RunJar**这个类的内容中，我们可以看到，如果在**META-INF/MANIFEST.MF**中包含了一个跟我们通过命令行指定的主类不相同的主类，那么是会优先选择**META-INF/MANIFEST.MF**中指定的那个主类的。

而我们编写的MapReduce作业中，一般主类中，都是通过**Job**对象来进行一些配置，并通过**job.waitForCompletion()**方法来等待其完成，并输出中间的过程信息。

关于“作业提交”这个阶段的具体过程，在**《Hadoop: The Definitive Guide》**这本书中，有一副非常清晰的过程图，这里我们将它摘取过来：

![](http://upload-images.jianshu.io/upload_images/4108852-d6ae6f958594f307.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

就算不看源码，只看这幅图片，也能对这个过程有一个清晰的认识。

在这篇文章中，我们主要介绍上图中的第1, 2, 3, 4步。后面的步骤，我们会在后面的文章中介绍。

我们首先看一下**Job**的**waitForCompletion(boolean verbose)**方法的实现。

![](http://upload-images.jianshu.io/upload_images/4108852-dd1afd061a3c0be7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在这个方法中，最重要的调用就是**submit()**这一行。

我们看一下**submit()**方法的实现。

![](http://upload-images.jianshu.io/upload_images/4108852-e950180dd08d01be.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中**connect()**方法，会根据你的配置文件，实例化一个**Cluster**类的对象，并将其赋给**Job.cluster**这个字段。我们可以通过**Cluster**来跟YARN这种集群资源管理系统交互。

这是因为**Cluster**中有一个**ClientProtocol**类型的字段，**ClientProtocol**就是用于Client和集群资源管理系统交互的工具，**ClientProtocol**有一个很重要的实现，就是**YARNRunner**。

我们可以看到，在**submit**方法中，获取到了一个**JobSubmitter**。然后通过**JobSubmitter**的**submitJobInternal()**方法来正式提交任务。

关于**submitJobInternal()**这个方法，在其注释中，就写的非常清楚了。

![](http://upload-images.jianshu.io/upload_images/4108852-53bf183c0b5787cc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们可以看到，它做了这么几件事情：
  - 检查作业的输入和输出
  - 计算**InputSplit**
  - 验证
  - 将作业的Jar文件，配置文件，以及一些其他的文件保存到DistributedCache中
  - 将作业提交的JobTracker上，并监控它的状态

我们这里主要介绍这么三点：
  - 计算**InputSplit**
  - 将作业的Jar文件，配置文件，以及一些其他的文件保存到DistributedCache中
  - 将作业提交的JobTracker上，并监控它的状态

我们先来看第二点-将作业的Jar文件、配置文件、以及一些其他的文件保存到DistributedCache中。

在这一点上，最重要的是一个叫做**copyAndConfigureFiles()**的方法，这个方法会将我们的作业的Jar文件，以及在命令行中，通过**-files，-libjars，-archives**指定的文件，加入到**DistributedCache**中。而**DistributedCache**实际上，就是DFS中的一个特殊的文件夹。它的命名规则是，**/tmp/hadoop-yarn/staging/<your_username>/.staging/<job_id>/files**

![](http://upload-images.jianshu.io/upload_images/4108852-f35d5ed8d9429564.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在把它们加到**DistributedCache**中之后，还会为它们设置权限等。并将路径信息保存到**Configuration**对象中。

还有很多跟这个作业相关的内容，也会被添加到这个跟此次作业相关的文件夹当中，比如，后面我们将会看到的，关于**InputSplit**的一些信息。

在这个方法内部，通过调用**writeSplits()**方法，来进行分片。

![](http://upload-images.jianshu.io/upload_images/4108852-245124fdbb09d7d0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们可以看到，就是调用了**InputFormat**的**getSplits()**方法而已，最后再对各个**InputSplit**进行排序，将最大的排到前面。

在这个方法的最后，我们可以看到，调用了**ClientProtocol**的**submitJob()**方法来提交作业。

![](http://upload-images.jianshu.io/upload_images/4108852-8b3922e860912232.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这个方法中，最重要的就是调用**createApplicationSubmissionContext()**方法来构造**ApplicationSubmissionContext**以及**ContainerLaunchContext**这两个非常重要的对象了。

这两个对象为什么重要呢？
  - **ApplicationSubmissionContext**这个对象，包含了**YARN ResourceManager**启动**ApplicationMaster**的全部信息。**ApplicationMaster**也是一个非常重要的组件，它相当于Mapper和Reducer中间的桥梁。
  - **ContainerLaunchContext**这个对象，包含了**YARN NodeManager**启动一个Container所需要的全部信息，包括需要运行的命令，以及**CLASSPATH**等。

在构造好这两个对象之后，将**ContainerLaunchContext**包含在**ApplicationSubmissionContext**中，然后通过Protobuf这种RPC调用，将**ApplicationSubmissionContext**发送给**YARN ResourceManager**，来启动一个任务。

然后，再通过获取任务状态的RPC调用，来获取这个任务的状态。

一个任务的状态，有这么几种：
  - **NEW**：表示任务刚被创建
  - **NEW_SAVING**：表示任务已经被保存
  - **SUBMITTED**：表示任务已经被提交
  - **ACCEPTED**：表示任务已经被调度器接受
  - **RUNNING**：表示任务正在运行
  - **FINISHED**：表示任务已经正常完成
  - **FAILED**：表示任务失败
  - **KILLED**：表示任务已经被用户或者管理员取消

只要任务不是处于**NEW**或者**NEW_SAVING**状态，那么就给Client返回。也就是说，不管任务是成功还是失败，都给Client返回。

然后，客户端再通过不断向**YARN ResourceManager**轮循任务的状态，在控制台输出进度等。

## 思考

从Hadoop的实现中，可以看到，我们可以很轻松的添加其他的集群资源管理系统，可以替换掉YARN，而采用Mesos，或者Kubernetes等。

但是，目前Hadoop的实现中，只支持YARN。

## 参考资料
《Hadoop: The Definitive Guide》
